{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "\n",
    "#### References\n",
    "* https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "* https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "* https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.6.0\n",
      "Torchvision Version:  0.7.0\n",
      "Device: cuda:0\n",
      "Number of GPUs Available: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import models\n",
    "import losses\n",
    "import utils_train\n",
    "import change_dataset_np\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "\n",
    "import helper_augmentations\n",
    "\n",
    "from IPython.display import clear_output, display\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 50\n",
    "num_classes = 2\n",
    "batch_size = 20\n",
    "img_size = 224\n",
    "base_lr = 1e-4\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', device)\n",
    "#num_gpu = torch.cuda.device_count()\n",
    "num_gpu = 1\n",
    "batch_size *= num_gpu\n",
    "base_lr *= num_gpu\n",
    "print('Number of GPUs Available:', num_gpu)\n",
    "\n",
    "train_pickle_file = './change_dataset_train.pkl'\n",
    "val_pickle_file = './change_dataset_val.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        #transforms.RandomResizedCrop(img_size),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        #helper_augmentations.SwapReferenceTest(),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0, hue=0),\n",
    "        #helper_augmentations.JitterGamma(),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation datasets\n",
    "train_dataset = change_dataset_np.ChangeDatasetNumpy(train_pickle_file, data_transforms['train'])\n",
    "val_dataset = change_dataset_np.ChangeDatasetNumpy(val_pickle_file, data_transforms['val'])\n",
    "image_datasets = {'train': train_dataset, 'val': val_dataset}\n",
    "# Create training and validation dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=6)\n",
    "#dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=8) for x in ['train', 'val']}\n",
    "dataloaders_dict = {'train': train_loader, 'val': val_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Tensorboard Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default directory \"runs\"\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_reference_dummy = torch.randn(1,3,img_size,img_size)\n",
    "img_test_dummy = torch.randn(1,3,img_size,img_size)\n",
    "change_net = models.ChangeNet(num_classes=num_classes)\n",
    "\n",
    "# Add on Tensorboard the Model Graph\n",
    "writer.add_graph(change_net, [[img_reference_dummy, img_test_dummy]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Send Model to GPUs (If Available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if num_gpu > 1:\n",
    "#    change_net = nn.DataParallel(change_net)\n",
    "change_net = change_net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointname = './best_model'+str(num_classes)+'.pkl'\n",
    "import os.path\n",
    "\n",
    "if os.path.exists((checkpointname)):\n",
    "    checkpoint = torch.load(checkpointname)\n",
    "    change_net.load_state_dict(checkpoint);\n",
    "    print('Checkpoint '+checkpointname+' is loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Loss Functions and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.CrossEntropyLoss()\n",
    "# If there are more than 2 classes the alpha need to be a list\n",
    "criterion = losses.FocalLoss(gamma=2.0, alpha=0.25)\n",
    "optimizer = optim.Adam(change_net.parameters(), lr=base_lr)    \n",
    "sc_plt = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "labels (pre squeeze) : torch.Size([20, 1, 224, 224]) ref : torch.Size([20, 3, 224, 224])\n",
      "labels : torch.Size([20, 224, 224])\n",
      "output from model:  torch.Size([20, 2, 224, 224])\n",
      "input (pre):  torch.Size([20, 2, 224, 224])\n",
      "target : torch.Size([1003520, 1]) input :  torch.Size([1003520, 2])\n",
      "labels (pre squeeze) : torch.Size([20, 1, 224, 224]) ref : torch.Size([20, 3, 224, 224])\n",
      "labels : torch.Size([20, 224, 224])\n",
      "output from model:  torch.Size([20, 2, 224, 224])\n",
      "input (pre):  torch.Size([20, 2, 224, 224])\n",
      "target : torch.Size([1003520, 1]) input :  torch.Size([1003520, 2])\n",
      "labels (pre squeeze) : torch.Size([20, 1, 224, 224]) ref : torch.Size([20, 3, 224, 224])\n",
      "labels : torch.Size([20, 224, 224])\n",
      "output from model:  torch.Size([20, 2, 224, 224])\n",
      "input (pre):  torch.Size([20, 2, 224, 224])\n",
      "target : torch.Size([1003520, 1]) input :  torch.Size([1003520, 2])\n",
      "labels (pre squeeze) : torch.Size([20, 1, 224, 224]) ref : torch.Size([20, 3, 224, 224])\n",
      "labels : torch.Size([20, 224, 224])\n",
      "output from model:  torch.Size([20, 2, 224, 224])\n",
      "input (pre):  torch.Size([20, 2, 224, 224])\n",
      "target : torch.Size([1003520, 1]) input :  torch.Size([1003520, 2])\n",
      "labels (pre squeeze) : torch.Size([18, 1, 224, 224]) ref : torch.Size([18, 3, 224, 224])\n",
      "labels : torch.Size([18, 224, 224])\n",
      "output from model:  torch.Size([18, 2, 224, 224])\n",
      "input (pre):  torch.Size([18, 2, 224, 224])\n",
      "target : torch.Size([903168, 1]) input :  torch.Size([903168, 2])\n",
      "train Loss: 0.0112\n",
      "labels (pre squeeze) : torch.Size([20, 1, 224, 224]) ref : torch.Size([20, 3, 224, 224])\n",
      "labels : torch.Size([20, 224, 224])\n",
      "output from model:  torch.Size([20, 2, 224, 224])\n",
      "input (pre):  torch.Size([20, 2, 224, 224])\n",
      "target : torch.Size([1003520, 1]) input :  torch.Size([1003520, 2])\n",
      "labels (pre squeeze) : torch.Size([20, 1, 224, 224]) ref : torch.Size([20, 3, 224, 224])\n",
      "labels : torch.Size([20, 224, 224])\n",
      "output from model:  torch.Size([20, 2, 224, 224])\n",
      "input (pre):  torch.Size([20, 2, 224, 224])\n",
      "target : torch.Size([1003520, 1]) input :  torch.Size([1003520, 2])\n",
      "labels (pre squeeze) : torch.Size([14, 1, 224, 224]) ref : torch.Size([14, 3, 224, 224])\n",
      "labels : torch.Size([14, 224, 224])\n",
      "output from model:  torch.Size([14, 2, 224, 224])\n",
      "input (pre):  torch.Size([14, 2, 224, 224])\n",
      "target : torch.Size([702464, 1]) input :  torch.Size([702464, 2])\n",
      "val Loss: 0.0325\n",
      "Best val Acc: 45948.870370\n"
     ]
    }
   ],
   "source": [
    "best_model, _ = utils_train.train_model(change_net, dataloaders_dict, criterion, optimizer, sc_plt, writer, device, num_epochs=num_epochs)\n",
    "torch.save(best_model.state_dict(), './best_model'+str(num_classes)+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507c740eca4145f994f9554e883a89ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='idx', max=53), Checkbox(value=False, description='inv'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(idx=widgets.IntSlider(min=0,max=len(val_dataset)-1), inv=widgets.Checkbox())\n",
    "def explore_validation_dataset(idx, inv):\n",
    "    best_model.eval()\n",
    "    sample = val_dataset[idx]\n",
    "    if not inv:\n",
    "        reference = sample['reference'].unsqueeze(0).to(device)\n",
    "        reference_img = sample['reference'].permute(1, 2, 0).cpu().numpy()\n",
    "        test_img = sample['test'].permute(1, 2, 0).cpu().numpy()\n",
    "        test = sample['test'].unsqueeze(0).to(device)\n",
    "    else:\n",
    "        reference = sample['test'].unsqueeze(0).to(device)\n",
    "        reference_img = sample['test'].permute(1, 2, 0).cpu().numpy()\n",
    "        test_img = sample['reference'].permute(1, 2, 0).cpu().numpy()\n",
    "        test = sample['reference'].unsqueeze(0).to(device)\n",
    "        \n",
    "    #label = sample['label'].type(torch.LongTensor).squeeze(0).cpu().numpy()\n",
    "    label = (sample['label']>0).type(torch.LongTensor).squeeze(0).cpu().numpy()\n",
    "    pred = best_model([reference, test])\n",
    "    #print(pred.shape)\n",
    "    _, output = torch.max(pred, 1)\n",
    "    output = output.squeeze(0).cpu().numpy()\n",
    "    fig=plt.figure(figsize=(8, 8))\n",
    "    fig.add_subplot(2, 2, 1)\n",
    "    plt.imshow(reference_img)\n",
    "    plt.title('Reference')\n",
    "    fig.add_subplot(2, 2, 2)\n",
    "    plt.imshow(test_img)\n",
    "    plt.title('Test')\n",
    "    fig.add_subplot(2, 2, 3)\n",
    "    plt.imshow(label, )\n",
    "    plt.title('Label')\n",
    "    fig.add_subplot(2, 2, 4)\n",
    "    plt.imshow(output)\n",
    "    plt.title('ChangeNet Output')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
